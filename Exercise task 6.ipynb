{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5UL+QYBnt420VWLsJC1cr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Deep-Learning-in-Human-Language-Technology/blob/main/Exercise%20task%206.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural attention\n",
        "\n",
        "Read the paper Neural Machine Translation by Jointly Learning to Align and Translate, which introduces the neural attention.\n",
        "\n",
        "Answer the following questions:"
      ],
      "metadata": {
        "id": "Rv8xAGThGGNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Which datasets are used in training and evaluation (size, language, etc.)?\n",
        "\n",
        "WMT ’14 contains the following English-French parallel corpora: Europarl (61M words), news commentary (5.5M), UN (421M) and two crawled corpora of 90M and 272.5M words respectively, totaling 850M words."
      ],
      "metadata": {
        "id": "-kuM30cEGNYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Which neural model architectures are evaluated in the paper?\n",
        "\n",
        "\n",
        "\n",
        "*   RNN Encoder–Decoder\n",
        "*   as well as their own one called as RNNsearch\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hq6a3nOTGKKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Briefly summarize the results and the used metric. Did the neural attention improve the results compared to the previously existing models?\n",
        "\n",
        "the translation performances measured in BLEU score\n",
        "As could be seen below, the proposed model has improved performance rather than RNNencode model.\n",
        "\n",
        "*   Model          BLEU scores\n",
        "* RNNencdec-30    13.93\n",
        "* RNNsearch-30    21.50\n",
        "* RNNencdec-50    17.82\n",
        "* RNNsearch-50    26.75\n",
        "\n"
      ],
      "metadata": {
        "id": "MR8nLZuWGIjc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lzYsG5opHwsM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}